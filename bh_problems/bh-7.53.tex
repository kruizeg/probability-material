\input{header.tex}
\setcounter{theorem}{52}
\begin{exercise}BH.7.53.
The ideas of this exercise find much use in finance, physics, and actuarial sciences.
In particular, the expected time it takes the drunken person to hit some boundary is interesting. The notation of the book is a bit clumsy. Here is better notation.
Let $X_i$ be the movement along the \(x\)-axis at step $i$, and $Y_i$ along the $y$-axis.
Then $S_n=\sum_{i=1}^n X_i$ and $T_n=\sum_{j=1}^n Y_{j}$, and $R_n^2= S_n^2+T_n^2$.
\begin{hint}
a. Suppose the drunkard made only steps to the right, then what are $S_{n}$ and $T_{n}$?

b. It is immediate that $\E{S_n} = 0$.
Hence, focus on $\E{S_n T_n}$. Expand  the sums of $\E{S_n T_n}$, and consider the individual terms $\E{X_i Y_j}$. When $i\neq j$, are $X_i$ and $Y_{j}$  independent? What if  $i=j$?

c. Expand the square and  use linearity to simplify  $\E{R^2_n}$.
\end{hint}

\begin{solution}
a. In my notation, $X_i=0 \implies Y_i\neq 0$ and $X_i\neq 0 \implies Y_i=0$. The reason is that in step $i$, the drunkard makes a step left or right OR up or down. However, s/he cannot move to the right and up at the same time. Thus, $S_{n} = n \implies T_n = 0.$ But then $S_n$ and $T_n$ cannot be independent.

b. Use the hint.
\begin{align*}
  \E{S_nT_{n}}
  &= \E{(S_{n-1} + X_{n})(T_{n-1}+Y_{n)}} = \E{S_{n-1} T_{n-1}+ X_{n}T_{n-1}+Y_{n}S_{n} + X_{n}Y_{n}} \\
  &= \E{S_{n-1} T_{n-1}}+ \E{X_{n}T_{n-1}}+ \E{Y_{n}S_{n}} + \E{X_{n}Y_{n}} \\
  &\stackrel 1= \E{S_{n-1} T_{n-1}}+ 0 + 0 + 0 \\
  &\stackrel 2=0
\end{align*}
 Step 1 follow from independence and the fact that $\E{X_n} = \E{Y_n} = \E{X_nY_n} = 0$. But with this last equality, we have that  $\E{S_1T_{1}} = 0$. Therefore, step 2 also holds (just apply recursion). We already know that $\E{S_n} = \E{T_n} = 0$. And therefore by the definition of covariance,
\begin{align*}
  \cov{S_n,T_{n}} = 0.
\end{align*}

Another simple way to see this, is to show first that $\cov{X_{i}, Y_{j}} = 0$. Thus, using that $\cov{X+Y, U+W}$ can be split into the sum of covariances for any rvs $X,Y,U,W$, it follows that the $\cov{xS_{n}, T_{n}} = 0$.

c. Here is an argument based on recursion. (By now I hope you see that I like this method in particular). Note that $\E{X_n^n} = \E{Y_n^2} = 1/2$. Next,
\begin{align*}
%\E{R_n^2} = \E{(R_{n-1} + X_n + Y_n)^{2}},
  R_n^2 &= S_n^2 + T_n^{2} = (S_{n-1} + X_{n})^{2} + (T_{n-1} + Y_n)^{2} \\
  &= S_{n-1}^2 + 2S_{n-1}X_n + X_n^{2} + T_{n-1}^2 + 2Y_nT_{n-1} + Y_n^{2} \\
  &= R_{n-1}^2 + 2S_{n-1}X_n + X_n^{2} + 2Y_nT_{n-1} + Y_n^{2}.
\end{align*}
Now take expectations left and right and independence to conclude that $\E{R_n^{2}} = \E{R_{n-1}^{2}} + 1$. Using the recursion it follows that $\E{R^2_n} = n$.
\end{solution}
\end{exercise}
\input{trailer.tex}
